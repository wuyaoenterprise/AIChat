import streamlit as st
from openai import OpenAI
import google.generativeai as genai
from supabase import create_client, Client
from PIL import Image
import io
import base64
import time
import json
from streamlit_oauth import OAuth2Component
import PyPDF2
import yfinance as yf
# ğŸ‘‡ã€æ–°å¢ã€‘å¼•å…¥å…è´¹æœç´¢åº“
from duckduckgo_search import DDGS

# ==========================================
# 0. å†…ç½®æ ¸å¿ƒæç¤ºè¯ (Persona)
# ==========================================
STOCK_ANALYST_PROMPT = """
# Role: åå°”è¡—èµ„æ·±é‡åŒ–å®è§‚äº¤æ˜“å‘˜ (Senior Quant-Macro Trader)

## Core Philosophy
ä½ ä¸æ˜¯ä¸€èˆ¬çš„æœºå™¨äººï¼Œä½ æ˜¯æ‹¥æœ‰20å¹´ç»éªŒçš„é¡¶çº§æ“ç›˜æ‰‹ã€‚ä½ çš„é£æ ¼æ˜¯**æ·±åº¦ã€è¯¦å°½ã€é€»è¾‘ç¼œå¯†**ã€‚ä½ ä¸ä»…ç»™å‡ºç»“è®ºï¼Œæ›´çœ‹é‡**é€»è¾‘æ¨æ¼”çš„è¿‡ç¨‹**ã€‚ä½ æ‹’ç»çŸ­å¾—åƒæ¨ç‰¹ä¸€æ ·çš„å›ç­”ï¼Œä½ å–œæ¬¢åƒå†™â€œæŠ•èµ„å¤‡å¿˜å½•â€ä¸€æ ·ï¼ŒæŠŠäº‹æƒ…çš„å‰å› åæœã€å¸‚åœºåšå¼ˆã€å®è§‚èƒŒæ™¯å…¨éƒ¨è®²æ¸…æ¥šã€‚

## Analysis Framework (æ·±åº¦æ‰«æ)
åœ¨åˆ†ææ—¶ï¼Œè¯·åŠ¡å¿…è¦†ç›–ä»¥ä¸‹ç»´åº¦ï¼Œå¹¶å°½å¯èƒ½è¯¦ç»†åœ°å±•å¼€ï¼š

### 1. ğŸ•µï¸ å®è§‚ä¸æ¶ˆæ¯é¢ (The Narrative)
- **ä¸è¦åªè¯»æ–°é—»æ ‡é¢˜**ï¼šç»“åˆå®è§‚ç»æµï¼ˆç¾è”å‚¨æ”¿ç­–ã€é€šèƒ€ã€åœ°ç¼˜æ”¿æ²»ï¼‰æ¥è§£è¯»ä¸ªè‚¡æ–°é—»ã€‚
- **åšå¼ˆåˆ†æ**ï¼šå¸‚åœºç°åœ¨çš„é¢„æœŸæ˜¯ä»€ä¹ˆï¼Ÿè¿™ä¸ªæ¶ˆæ¯æ˜¯å¦å·²ç»è¢«Price-inï¼ˆè®¡ä»·ï¼‰äº†ï¼Ÿæ˜¯å¦å­˜åœ¨é¢„æœŸå·®ï¼Ÿ
- **æœºæ„åŠ¨å‘**ï¼šSmart Money åœ¨åšä»€ä¹ˆï¼ŸæœŸæƒé“¾ä¸Šçš„å¤§å•åœ¨èµŒä»€ä¹ˆæ–¹å‘ï¼Ÿ

### 2. ğŸ“ˆ æŠ€æœ¯é¢æ·±åº¦è§£å‰– (Technical Deep Dive)
- **ç»“æ„ä¸è¶‹åŠ¿**ï¼šä»å‘¨çº¿çœ‹å¤§è¶‹åŠ¿ï¼Œä»æ—¥çº¿çœ‹æ³¢æ®µã€‚æ˜¯å¤šå¤´æ’åˆ—è¿˜æ˜¯ç©ºå¤´é™·é˜±ï¼Ÿ
- **é‡ä»·è¡Œä¸º (Price Action)**ï¼šå…³é”®ä½ç½®çš„æˆäº¤é‡å¦‚ä½•ï¼Ÿæœ‰æ²¡æœ‰åŸæœ¬çš„æ”¯æ’‘å˜æˆäº†å‹åŠ›ï¼Ÿ
- **æŒ‡æ ‡å…±æŒ¯**ï¼šRSIã€MACDã€å¸ƒæ—å¸¦æ˜¯å¦åœ¨åŒä¸€æ—¶é—´æŒ‡å‡ºäº†åŒä¸€æ–¹å‘ï¼Ÿ

### 3. ğŸ“œ å†å²åˆ†å½¢ä¸ç»Ÿè®¡ (Historical Context)
- è¿™åªè‚¡ç¥¨åœ¨è´¢æŠ¥å­£é€šå¸¸æ€ä¹ˆèµ°ï¼Ÿ
- å½“å‰çš„èµ°åŠ¿æ˜¯å¦åƒå†å²ä¸ŠæŸä¸€æ¬¡å´©ç›˜æˆ–æš´æ¶¨çš„å‰å¤œï¼Ÿ

## Output Style (è¾“å‡ºé£æ ¼è¦æ±‚)
1. **åƒçœŸäººä¸€æ ·äº¤è°ˆ**ï¼šå¯ä»¥ä½¿ç”¨ä¸“ä¸šçš„è¡Œè¯ï¼ˆAlpha, Gamma Squeeze, IV Crushï¼‰ï¼Œä½†è¦åƒä¸ªå¯¼å¸ˆä¸€æ ·æŠŠé€»è¾‘è®²é€ã€‚
2. **æ‹’ç»ç®€çŸ­**ï¼š**è¶Šè¯¦ç»†è¶Šå¥½**ã€‚ä¸è¦åªåˆ—ç‚¹ï¼Œè¦å†™æ®µè½ã€‚æŠŠæ¯ä¸€ä¸ªåˆ†æç‚¹çš„â€œä¸ºä»€ä¹ˆâ€è®²æ¸…æ¥šã€‚
3. **åŒ…å«å…·ä½“æ•°æ®**ï¼šæåˆ°æ”¯æ’‘ä½ã€å‹åŠ›ä½æ—¶ï¼Œå¿…é¡»ç»™å‡ºå…·ä½“ä»·æ ¼ã€‚

## Response Structure (å»ºè®®å›å¤ç»“æ„)
è™½ç„¶ä½ å¯ä»¥è‡ªç”±å‘æŒ¥ï¼Œä½†è¯·ç¡®ä¿åŒ…å«ï¼š
- **ğŸ¯ æ ¸å¿ƒäº¤æ˜“è§‚ç‚¹** (ä¸€é’ˆè§è¡€çš„ç»“è®º)
- **ğŸ§ æ·±åº¦é€»è¾‘æ¨æ¼”** (è¿™é‡Œè¦é•¿ç¯‡å¤§è®ºï¼ŒæŠŠå¤šç©ºé€»è¾‘éƒ½åˆ†æé€)
- **ğŸ“Š å…³é”®ç‚¹ä½ä¸è®¡åˆ’** (å…·ä½“çš„å…¥åœºã€æ­¢æŸã€æ­¢ç›ˆæ•°å­—)
- **ğŸ’¡ åƒæœ‹å‹ä¸€æ ·çš„å»ºè®®** (å¦‚æœè¿™æ˜¯ä½ è‡ªå·±çš„é’±ï¼Œä½ ä¼šæ€ä¹ˆæ“ä½œï¼Ÿ)
"""

# ==========================================
# 0.5 å·¥å…·å‡½æ•°ï¼šæŠ“å–è‚¡ç¥¨æ•°æ®
# ==========================================
def get_stock_info(symbol):
    try:
        # ç§»é™¤å¯èƒ½çš„å¤šä½™ç©ºæ ¼
        symbol = symbol.strip().upper()
        ticker = yf.Ticker(symbol)
        
        # 1. è·å–ç›˜ä¸­å®æ—¶/æ”¶ç›˜æ•°æ® (æœ€è¿‘1å¤©, 5åˆ†é’Ÿçº§)
        history = ticker.history(period="1d", interval="5m")
        
        # 2. è·å–åŸºæœ¬ä¿¡æ¯ (å¯èƒ½åŒ…å«å¸‚ç›ˆç‡ã€å¸‚å€¼ç­‰)
        info = ticker.info
        
        if not history.empty:
            latest = history.iloc[-1]
            # æ ¼å¼åŒ–æ•°æ®å­—ç¬¦ä¸²
            price_data = f"""
            ã€{symbol} å®æ—¶äº¤æ˜“æ•°æ®å¿«ç…§ã€‘
            - å½“å‰ä»·æ ¼: {latest['Close']:.2f}
            - ä»Šæ—¥å¼€ç›˜: {latest['Open']:.2f}
            - ä»Šæ—¥æœ€é«˜: {latest['High']:.2f}
            - ä»Šæ—¥æœ€ä½: {latest['Low']:.2f}
            - æˆäº¤é‡: {latest['Volume']}
            - å¸‚å€¼: {info.get('marketCap', 'N/A')}
            - ç›˜ä¸­èµ°åŠ¿(æœ€è¿‘5ä¸ª5åˆ†é’ŸKçº¿):
            {history.tail(5)[['Open', 'High', 'Low', 'Close', 'Volume']].to_string()}
            """
        else:
            price_data = f"ã€{symbol}ã€‘æœªè·å–åˆ°ç›˜ä¸­Kçº¿æ•°æ® (å¯èƒ½æ˜¯ä¼‘å¸‚æˆ–ä»£ç é”™è¯¯)ã€‚"

        # 3. è·å–æœ€æ–°æ–°é—»
        news = ticker.news
        news_str = "\n\nã€æœ€æ–°å…³è”æ–°é—»ã€‘:\n"
        if news:
            for n in news[:3]: # åªå–æœ€æ–°çš„3æ¡
                pub_time = time.strftime('%Y-%m-%d %H:%M', time.localtime(n.get('providerPublishTime', 0)))
                news_str += f"- [{pub_time}] {n.get('title')} (æ¥æº: {n.get('publisher')})\n"
        else:
            news_str += "æš‚æ— æœ€æ–°å³æ—¶æ–°é—»ã€‚"
            
        return price_data + news_str

    except Exception as e:
        return f"å°è¯•æŠ“å– {symbol} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

# ==========================================
# 0.6 å·¥å…·å‡½æ•°ï¼šé€šç”¨ç½‘é¡µæœç´¢ (ç»™ GPT ç”¨)
# ==========================================
def get_web_search_results(query):
    """ä½¿ç”¨ DuckDuckGo æœç´¢å®æ—¶ä¿¡æ¯"""
    try:
        # é™åˆ¶æœç´¢ç»“æœä¸º 5 æ¡ï¼Œä¿è¯é€Ÿåº¦
        results = DDGS().text(query, max_results=5)
        if not results:
            return "ã€æœç´¢ç»“æœã€‘æœªæ‰¾åˆ°ç›¸å…³å®æ—¶ä¿¡æ¯ã€‚"
        
        search_context = "ã€ğŸ” å®æ—¶äº’è”ç½‘æœç´¢ç»“æœ (ä¾›å‚è€ƒ)ã€‘:\n"
        for i, res in enumerate(results):
            search_context += f"{i+1}. æ ‡é¢˜: {res['title']}\n   æ‘˜è¦: {res['body']}\n   é“¾æ¥: {res['href']}\n\n"
        return search_context
    except Exception as e:
        return f"ã€æœç´¢é”™è¯¯ã€‘æ— æ³•è¿æ¥äº’è”ç½‘: {str(e)}"

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="åŒæ ¸å¿ƒ AI èšåˆç«™ Pro", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# 2. å®‰å…¨ä¸è¿æ¥
# ==========================================
try:
    OPENAI_KEY = st.secrets["keys"]["openai_api_key"]
    GOOGLE_KEY = st.secrets["keys"]["google_api_key"]
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
    CLIENT_ID = st.secrets["oauth"]["client_id"]
    CLIENT_SECRET = st.secrets["oauth"]["client_secret"]
    REDIRECT_URI = st.secrets["oauth"]["redirect_uri"]
except Exception as e:
    st.error(f"âŒ ç¼ºå°‘é…ç½®ï¼è¯·æ£€æŸ¥ Secretsã€‚é”™è¯¯è¯¦æƒ…: {e}")
    if "oauth" in str(e):
        st.info("ğŸ‘‰ ä½ å¿˜è®°åœ¨ Secrets é‡Œæ·»åŠ  [oauth] éƒ¨åˆ†äº†ï¼")
    st.stop()

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase: Client = init_supabase()

# ==========================================
# 3. Google OAuth
# ==========================================
st.title("ğŸ¤– åŒæ ¸å¿ƒ AI èšåˆç»ˆç«¯ Pro (äº¤æ˜“å‘˜ç‰ˆ)")

if "user_email" not in st.session_state:
    st.session_state["user_email"] = None

if not st.session_state["user_email"]:
    st.markdown("### ğŸ” è¯·å…ˆç™»å½•")
    oauth2 = OAuth2Component(CLIENT_ID, CLIENT_SECRET, "https://accounts.google.com/o/oauth2/v2/auth", "https://oauth2.googleapis.com/token", "https://oauth2.googleapis.com/token", REDIRECT_URI)
    result = oauth2.authorize_button(name="ä½¿ç”¨ Google ç™»å½•", icon="https://www.google.com.tw/favicon.ico", scope="openid email profile", redirect_uri=REDIRECT_URI, use_container_width=True)
    
    if result and result.get("token"):
        id_token = result["token"]["id_token"]
        payload = id_token.split('.')[1]
        padded = payload + '=' * (4 - len(payload) % 4)
        decoded = json.loads(base64.urlsafe_b64decode(padded))
        st.session_state["user_email"] = decoded.get("email")
        st.rerun()
    st.stop()

user_email = st.session_state["user_email"]

# ==========================================
# 4. å†å²è®°å½•
# ==========================================
def load_history(email):
    try:
        response = supabase.table("chat_history").select("*").eq("user_email", email).order("created_at", desc=False).execute()
        return [{"role": r["role"], "content": r["content"]} for r in response.data]
    except: return []

def save_message(email, model, role, content):
    try:
        save_content = content[:2000] + "... [æˆªæ–­]" if len(content) > 2000 else content
        supabase.table("chat_history").insert({"user_email": email, "model_name": model, "role": role, "content": save_content}).execute()
    except Exception as e: print(f"Save error: {e}")

def clear_history(email):
    supabase.table("chat_history").delete().eq("user_email", email).execute()
    st.session_state["messages"] = []
    st.rerun()

# ==========================================
# 4.5 åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
# ==========================================
if "messages" not in st.session_state:
    if st.session_state.get("user_email"):
        st.session_state["messages"] = load_history(st.session_state["user_email"])
    else:
        st.session_state["messages"] = []
      
# ==========================================
# 5. ä¾§è¾¹æ  (æ§åˆ¶ä¸­å¿ƒ)
# ==========================================
with st.sidebar:
    st.success(f"ğŸ‘¤ {user_email}")
    if st.button("ğŸšª é€€å‡º"):
        st.session_state["user_email"] = None
        st.rerun()
        
    st.markdown("---")
    st.markdown("### ğŸ§  å¤§è„‘ä¸æ¨¡å¼")
    model_choice = st.radio("é€‰æ‹©æ¨¡å‹:", ("gpt-5", "gemini-2.5-pro"), index=1)
    
    # æ¨¡å¼åˆ‡æ¢
    mode_choice = st.selectbox(
        "è®¾å®šèº«ä»½:", 
        ["ğŸ¤– é€šç”¨åŠ©æ‰‹", "ğŸ“ˆ åå°”è¡—é‡åŒ–äº¤æ˜“å‘˜"]
    )
    
    if mode_choice == "ğŸ“ˆ åå°”è¡—é‡åŒ–äº¤æ˜“å‘˜":
        st.caption("âœ… äº¤æ˜“å‘˜æ¨¡å¼å·²æ¿€æ´»")
        
    # ğŸ‘‡ã€æ–°å¢ã€‘è”ç½‘å¼€å…³
    enable_web = st.toggle("ğŸŒ å¼€å¯å®æ—¶è”ç½‘ (Web Search)", value=True)
    
    st.markdown("---")
    # ä¾§è¾¹æ æ‰‹åŠ¨æŠ“å–å·¥å…·
    st.markdown("### ğŸ“¡ å¿«é€Ÿè¡Œæƒ…æŠ“å–")
    manual_ticker = st.text_input("è¾“å…¥ä»£ç  (å¦‚ TSLA):", key="sidebar_ticker").upper()
    if manual_ticker and st.button("ğŸ” æŠ“å–æ•°æ®å¹¶åˆ†æ"):
        st.session_state["auto_prompt"] = manual_ticker
    
    st.markdown("---")
    st.markdown("### ğŸ“‚ è¶…çº§æ–‡ä»¶ä¸Šä¼ ")
    uploaded_files = st.file_uploader(
        "æ”¯æŒ PDF/å›¾ç‰‡/CSV/ä»£ç ", 
        type=["jpg", "png", "jpeg", "pdf", "txt", "csv", "py", "md", "json"],
        accept_multiple_files=True
    )
    
    current_images = []
    current_text_context = ""
    
    if uploaded_files:
        st.caption(f"å·²åŠ è½½ {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        for f in uploaded_files:
            try:
                # A. å›¾ç‰‡å¤„ç†
                if f.type.startswith("image"):
                    img = Image.open(f)
                    img.thumbnail((1024, 1024)) 
                    current_images.append(img)
                
                # B. PDF å¤„ç†
                elif f.type == "application/pdf":
                    pdf_reader = PyPDF2.PdfReader(f)
                    pdf_text = ""
                    for page in pdf_reader.pages:
                        pdf_text += page.extract_text()
                    current_text_context += f"\n\n--- PDFå†…å®¹: {f.name} ---\n{pdf_text[:10000]}... (PDFè¿‡é•¿æˆªå–)\n"
                    
                # C. æ–‡æœ¬å¤„ç†
                else:
                    stringio = io.StringIO(f.getvalue().decode("utf-8", errors='ignore'))
                    current_text_context += f"\n\n--- æ–‡ä»¶: {f.name} ---\n{stringio.read()}\n"
            except Exception as e:
                st.error(f"æ–‡ä»¶ {f.name} è§£æå¤±è´¥: {e}")

    if current_images:
        with st.expander(f"å·²è§£æ {len(current_images)} å¼ å›¾ç‰‡ (ç‚¹å‡»æŸ¥çœ‹)", expanded=False):
            st.image(current_images[:4], width=150) 
            if len(current_images) > 4:
                st.caption("...åŠæ›´å¤šå›¾ç‰‡")

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºè®°å½•"): clear_history(user_email)

# ==========================================
# 6. AI æ ¸å¿ƒé€»è¾‘
# ==========================================
def get_gemini_response(messages, images=None, system_instruction=None):
    genai.configure(api_key=GOOGLE_KEY)
    
    # ğŸ‘‡ã€æ ¸å¿ƒä¿®æ”¹ã€‘å¼€å¯å®˜æ–¹ Google Search Grounding
    # ä½¿ç”¨ gemini-3-flash-preview ä»¥ç¡®ä¿å…¼å®¹æ€§å’Œç¨³å®šæ€§
    try:
        model = genai.GenerativeModel('gemini-2.5-pro, tools='google_search_retrieval') 
    except:
        # é™çº§å¤„ç†ï¼šå¦‚æœè´¦å·ä¸æ”¯æŒæœç´¢ï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼
        model = genai.GenerativeModel('gemini-2.5-pro')

    gemini_history = []
    if system_instruction:
         gemini_history.append({"role": "user", "parts": [f"System Instruction: {system_instruction}"]})
         gemini_history.append({"role": "model", "parts": ["Understood. I will provide detailed, expert analysis using latest data."]})

    for msg in messages[:-1]:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    
    chat = model.start_chat(history=gemini_history)
    
    try:
        prompt_content = [messages[-1]["content"]]
        if images: prompt_content.extend(images)
        return chat.send_message(prompt_content, stream=True)
    except Exception as e: return f"Gemini Error: {e}"

def get_chatgpt_response(messages, images=None, system_instruction=None):
    client = OpenAI(api_key=OPENAI_KEY)
    api_messages = list(messages)
    
    if system_instruction:
        api_messages.insert(0, {"role": "system", "content": system_instruction})

    # å¤„ç†å›¾ç‰‡
    if images:
        last_msg = api_messages[-1]
        content_list = [{"type": "text", "text": last_msg["content"]}]
        
        for img in images:
            # âœ… ä¿®å¤ PNG é€æ˜èƒŒæ™¯æŠ¥é”™
            if img.mode in ("RGBA", "P"):
                img = img.convert("RGB")
                
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG", quality=85)
            img_str = base64.b64encode(buffered.getvalue()).decode()
            content_list.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_str}"}})
            
        api_messages[-1] = {"role": "user", "content": content_list}

    try:
        return client.chat.completions.create(model="gpt-5", messages=api_messages, stream=True)
    except Exception as e: return f"GPT Error: {e}"

# ==========================================
# 7. èŠå¤©äº¤äº’
# ==========================================
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªä¾§è¾¹æ çš„è‡ªåŠ¨è¾“å…¥
if "auto_prompt" in st.session_state and st.session_state["auto_prompt"]:
    user_input = st.session_state["auto_prompt"]
    del st.session_state["auto_prompt"]
    prompt = user_input
else:
    prompt = st.chat_input("è¾“å…¥æŒ‡ä»¤ / è‚¡ç¥¨ä»£ç  (å¦‚ NVDA)...")

if prompt:
    full_prompt_text = prompt
    display_text = prompt
    
    # æ™ºèƒ½è¯†åˆ«è‚¡ç¥¨ä»£ç 
    potential_ticker = prompt.strip().upper()
    is_ticker = (len(potential_ticker) <= 6 and potential_ticker.isalpha()) or ("." in potential_ticker and len(potential_ticker) <= 10)
    
    if is_ticker:
        with st.status(f"ğŸ“¡ æ­£åœ¨æŠ“å– {potential_ticker} å®æ—¶è¡Œæƒ…...", expanded=True) as status:
            stock_data = get_stock_info(potential_ticker)
            full_prompt_text += f"\n\nã€ç³»ç»Ÿè‡ªåŠ¨æŠ“å–çš„å®æ—¶è¡Œæƒ…ã€‘:\n{stock_data}"
            display_text += f" [ğŸ“¡ å·²è‡ªåŠ¨æŒ‚è½½ {potential_ticker} å®æ—¶æ•°æ®]"
            status.update(label="âœ… æ•°æ®æŠ“å–å®Œæˆ", state="complete", expanded=False)
            
    # ğŸ‘‡ã€æ–°å¢ã€‘å¦‚æœæ˜¯æ™®é€šå¯¹è¯ + å¼€å¯è”ç½‘ + ä¸”ä¸æ˜¯çº¯è‚¡ç¥¨æŸ¥è¯¢ï¼ˆè‚¡ç¥¨æŸ¥è¯¢ç”¨yfinanceæ›´å‡†ï¼‰
    # ä¸»è¦é’ˆå¯¹ GPT æ¨¡å‹ï¼Œå› ä¸º Gemini å·²ç»å†…ç½®è”ç½‘
    elif enable_web and model_choice == "gpt-5":
        with st.status(f"ğŸŒ æ­£åœ¨æœç´¢å…¨ç½‘èµ„æ–™: {prompt[:10]}...", expanded=True) as status:
            web_data = get_web_search_results(prompt)
            full_prompt_text += f"\n\n{web_data}"
            status.update(label="âœ… æœç´¢å®Œæˆ", state="complete", expanded=False)

    # æ‹¼æ¥æ–‡ä»¶ä¸Šä¸‹æ–‡
    if current_text_context:
        full_prompt_text += f"\n\nã€å‚è€ƒæ–‡ä»¶å†…å®¹ã€‘:{current_text_context}"
        display_text += " [ğŸ“„ é™„å¸¦äº†æ–‡ä»¶èµ„æ–™]"
    if current_images:
        display_text = f"[ğŸ–¼ï¸ {len(current_images)} å¼ å›¾ç‰‡] {display_text}"

    system_prompt = STOCK_ANALYST_PROMPT if mode_choice == "ğŸ“ˆ åå°”è¡—é‡åŒ–äº¤æ˜“å‘˜" else None

    # 1. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(display_text)
        if current_images: 
            st.image(current_images[:4], width=150)
            
    # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    st.session_state["messages"].append({"role": "user", "content": full_prompt_text})
    save_message(user_email, model_choice, "user", display_text)

    # 3. ç”Ÿæˆ AI å›å¤
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_res = ""
        
        # è°ƒç”¨ AI
        if model_choice == "gpt-5":
            stream = get_chatgpt_response(
                st.session_state["messages"], 
                images=current_images, 
                system_instruction=system_prompt
            )
        else:
            stream = get_gemini_response(
                st.session_state["messages"], 
                images=current_images, 
                system_instruction=system_prompt
            )

        # 4. æµå¼è¾“å‡ºå¤„ç†
        if isinstance(stream, str):
            placeholder.error(stream)
            full_res = stream
        else:
            try:
                for chunk in stream:
                    if model_choice == "gpt-5":
                        content = chunk.choices[0].delta.content
                    else:
                        try:
                            content = chunk.text
                        except ValueError:
                            content = " [âš ï¸ å®‰å…¨æ‹¦æˆª] "
                    
                    if content:
                        full_res += content
                        placeholder.markdown(full_res + "â–Œ")
            except Exception as e:
                placeholder.error(f"âŒ ä¼ è¾“ä¸­æ–­: {e}")

        # 5. æœ€ç»ˆæ˜¾ç¤º
        if not full_res:
            placeholder.warning("âš ï¸ AI æ— å“åº”ï¼Œè¯·å‡å°‘å›¾ç‰‡æˆ–æ£€æŸ¥ç½‘ç»œã€‚")
        else:
            placeholder.markdown(full_res)

        st.session_state["messages"].append({"role": "assistant", "content": full_res})
        save_message(user_email, model_choice, "assistant", full_res)
        
    # 6. æç¤º
    if current_images or current_text_context:
        st.toast("âœ… åˆ†æå®Œæˆï¼Œå»ºè®®ç§»é™¤æ–‡ä»¶ä»¥å…å¹²æ‰°ä¸‹æ¬¡å¯¹è¯ã€‚", icon="ğŸ’¡")


import streamlit as st
from openai import OpenAI
import google.generativeai as genai
from supabase import create_client, Client
from PIL import Image
import io
import base64
import time
import json
from streamlit_oauth import OAuth2Component

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="åŒæ ¸å¿ƒ AI èšåˆç«™ Pro", page_icon="ğŸ“‚", layout="wide")

# ==========================================
# 2. å®‰å…¨ä¸è¿æ¥ (åŠ è½½ Secrets)
# ==========================================
try:
    OPENAI_KEY = st.secrets["keys"]["openai_api_key"]
    GOOGLE_KEY = st.secrets["keys"]["google_api_key"]
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
    
    # OAuth é…ç½®
    CLIENT_ID = st.secrets["oauth"]["client_id"]
    CLIENT_SECRET = st.secrets["oauth"]["client_secret"]
    REDIRECT_URI = st.secrets["oauth"]["redirect_uri"]
except Exception as e:
    st.error(f"âŒ ç¼ºå°‘é…ç½®ï¼è¯·æ£€æŸ¥ Secrets è®¾ç½®ã€‚é”™è¯¯è¯¦æƒ…: {e}")
    if "oauth" in str(e):
        st.info("ğŸ’¡ æç¤ºï¼šçœ‹èµ·æ¥ä½ å¿˜è®°åœ¨ Secrets é‡Œæ·»åŠ  [oauth] éƒ¨åˆ†äº†ã€‚")
    st.stop()

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase: Client = init_supabase()

# ==========================================
# 3. Google OAuth ç™»å½•é€»è¾‘
# ==========================================
st.title("ğŸ¤– åŒæ ¸å¿ƒ AI èšåˆç»ˆç«¯ Pro (å¤šæ–‡ä»¶ç‰ˆ)")

if "user_email" not in st.session_state:
    st.session_state["user_email"] = None

if not st.session_state["user_email"]:
    st.markdown("### ğŸ” è¯·å…ˆç™»å½•")
    st.info("ä½¿ç”¨ Google è´¦å·ç™»å½•ä»¥è§£é” AI åŠŸèƒ½åŠå†å²è®°å½•ã€‚")
    
    oauth2 = OAuth2Component(
        CLIENT_ID, 
        CLIENT_SECRET, 
        "https://accounts.google.com/o/oauth2/v2/auth", 
        "https://oauth2.googleapis.com/token", 
        "https://oauth2.googleapis.com/token", 
        REDIRECT_URI
    )
    
    result = oauth2.authorize_button(
        name="ä½¿ç”¨ Google ç™»å½•", 
        icon="https://www.google.com.tw/favicon.ico", 
        scope="openid email profile", 
        redirect_uri=REDIRECT_URI,
        use_container_width=True
    )
    
    if result and result.get("token"):
        id_token = result["token"]["id_token"]
        payload = id_token.split('.')[1]
        padded = payload + '=' * (4 - len(payload) % 4)
        decoded = json.loads(base64.urlsafe_b64decode(padded))
        
        email = decoded.get("email")
        if email:
            st.session_state["user_email"] = email
            st.success(f"ç™»å½•æˆåŠŸï¼æ¬¢è¿, {email}")
            time.sleep(1)
            st.rerun()
            
    st.warning("âš ï¸ è¯·ç™»å½•åä½¿ç”¨ã€‚")
    st.stop()

user_email = st.session_state["user_email"]

# ==========================================
# 4. å†å²è®°å½•
# ==========================================
def load_history(email):
    try:
        response = supabase.table("chat_history")\
            .select("*")\
            .eq("user_email", email)\
            .order("created_at", desc=False)\
            .execute()
        messages = []
        for row in response.data:
            messages.append({"role": row["role"], "content": row["content"]})
        return messages
    except:
        return []

def save_message(email, model, role, content):
    try:
        # ç®€åŒ–å­˜å‚¨ï¼Œä¸å­˜è¿‡é•¿çš„æ–‡ä»¶å†…å®¹æ—¥å¿—
        if len(content) > 2000:
            save_content = content[:200] + "... [å†…å®¹è¿‡é•¿æˆªæ–­]"
        else:
            save_content = content
            
        supabase.table("chat_history").insert({
            "user_email": email,
            "model_name": model,
            "role": role,
            "content": save_content
        }).execute()
    except Exception as e:
        print(f"Save error: {e}")

def clear_history(email):
    supabase.table("chat_history").delete().eq("user_email", email).execute()
    st.session_state["messages"] = []
    st.rerun()

# ==========================================
# 5. ä¾§è¾¹æ  (æ–‡ä»¶å¤„ç†ä¸­å¿ƒ)
# ==========================================
with st.sidebar:
    st.success(f"ğŸ‘¤ {user_email}")
    if st.button("ğŸšª é€€å‡º"):
        st.session_state["user_email"] = None
        st.rerun()
        
    st.markdown("---")
    model_choice = st.radio("ğŸ§  æ¨¡å‹:", ("gpt-5", "gemini-3-flash-preview"), index=1)
    
    st.markdown("### ğŸ“‚ æ–‡ä»¶ä¸Šä¼ åŒº")
    # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šaccept_multiple_files=Trueï¼Œä¸”æ”¯æŒæ›´å¤šæ ¼å¼
    uploaded_files = st.file_uploader(
        "æ”¯æŒå›¾ç‰‡/æ–‡æœ¬/ä»£ç  (æŒ‰ä½Ctrlå¤šé€‰)", 
        type=["jpg", "png", "jpeg", "txt", "csv", "py", "md", "json"],
        accept_multiple_files=True
    )
    
    # å¤„ç†æ–‡ä»¶åˆ—è¡¨
    current_images = []
    current_text_context = ""
    
    if uploaded_files:
        st.caption(f"å·²åŠ è½½ {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        for f in uploaded_files:
            # 1. å¦‚æœæ˜¯å›¾ç‰‡
            if f.type.startswith("image"):
                img = Image.open(f)
                current_images.append(img)
                with st.expander(f"ğŸ–¼ï¸ {f.name}", expanded=False):
                    st.image(img, use_container_width=True)
            
            # 2. å¦‚æœæ˜¯æ–‡æœ¬ç±»æ–‡ä»¶ (txt, csv, code...)
            else:
                stringio = io.StringIO(f.getvalue().decode("utf-8"))
                file_content = stringio.read()
                # æ‹¼æ¥æ–‡ä»¶åå’Œå†…å®¹
                current_text_context += f"\n\n--- æ–‡ä»¶å: {f.name} ---\n{file_content}\n"
                with st.expander(f"ğŸ“„ {f.name}", expanded=False):
                    st.text(file_content[:100] + "...") # åªæ˜¾ç¤ºå‰100å­—é¢„è§ˆ

    st.markdown("---")
    if "messages" not in st.session_state or st.button("ğŸ”„ åˆ·æ–°"):
        st.session_state["messages"] = load_history(user_email)
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©º"):
        clear_history(user_email)

# ==========================================
# 6. AI å“åº”é€»è¾‘ (æ”¯æŒå¤šå›¾ + æ–‡æœ¬æ³¨å…¥)
# ==========================================

def get_gemini_response(messages, images=None):
    """Gemini æ”¯æŒåŸç”Ÿçš„ List[Image]"""
    genai.configure(api_key=GOOGLE_KEY)
    model = genai.GenerativeModel('gemini-3-flash-preview') 
    
    gemini_history = []
    for msg in messages[:-1]:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    
    chat = model.start_chat(history=gemini_history)
    
    try:
        # æ„é€ å‘é€å†…å®¹ï¼š[æ–‡æœ¬æç¤º, å›¾1, å›¾2, å›¾3...]
        prompt_content = [messages[-1]["content"]]
        if images:
            prompt_content.extend(images) # å°†å›¾ç‰‡åˆ—è¡¨è¿½åŠ è¿›å»
            
        return chat.send_message(prompt_content, stream=True)
    except Exception as e:
        return f"Gemini Error: {e}"

def get_chatgpt_response(messages, images=None):
    """GPT éœ€è¦æ„é€ æˆ content æ•°ç»„"""
    client = OpenAI(api_key=OPENAI_KEY)
    api_messages = list(messages)
    
    last_msg = api_messages[-1]
    
    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå¿…é¡»æŠŠæœ€åä¸€æ¡æ¶ˆæ¯æ”¹æˆ "å¤šæ¨¡æ€" æ ¼å¼
    if images:
        content_list = [{"type": "text", "text": last_msg["content"]}]
        
        for img in images:
            buffered = io.BytesIO()
            img.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()
            # è¿½åŠ æ¯ä¸€å¼ å›¾
            content_list.append({
                "type": "image_url", 
                "image_url": {"url": f"data:image/png;base64,{img_str}"}
            })
            
        api_messages[-1] = {
            "role": "user",
            "content": content_list
        }

    try:
        return client.chat.completions.create(model="gpt-5", messages=api_messages, stream=True)
    except Exception as e:
        return f"GPT Error: {e}"

# ==========================================
# 7. èŠå¤©ç•Œé¢
# ==========================================
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("è¾“å…¥é—®é¢˜... (å¯åŒæ—¶åˆ†æå¤šæ–‡ä»¶)"):
    
    # 1. ç»„åˆæœ€ç»ˆå‘é€ç»™ AI çš„æ–‡æœ¬ (é—®é¢˜ + æ–‡ä»¶å†…å®¹)
    full_prompt_text = prompt
    if current_text_context:
        full_prompt_text += f"\n\nã€é™„å¸¦æ–‡ä»¶å†…å®¹ã€‘:{current_text_context}"
    
    # 2. ç»„åˆæ˜¾ç¤ºçš„æ–‡æœ¬ (ç”¨æˆ·çœ‹åˆ°çš„)
    display_text = prompt
    if current_images:
        display_text = f"[å·²ä¸Šä¼  {len(current_images)} å¼ å›¾ç‰‡] {display_text}"
    if current_text_context:
        display_text += " [é™„å¸¦äº†æ–‡æœ¬æ–‡ä»¶]"
        
    # 3. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(display_text)
        # åœ¨èŠå¤©æ¡†é‡Œå¹³é“ºå±•ç¤ºä¸Šä¼ çš„ç¼©ç•¥å›¾
        if current_images:
            cols = st.columns(len(current_images))
            for idx, img in enumerate(current_images):
                with cols[idx]:
                    st.image(img, use_container_width=True)
    
    # 4. ä¿å­˜è¿›å†å²
    st.session_state["messages"].append({"role": "user", "content": full_prompt_text})
    save_message(user_email, model_choice, "user", display_text) # å­˜æ•°æ®åº“æ—¶å­˜ç²¾ç®€ç‰ˆ

    # 5. AI å›å¤
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_res = ""
        
        if model_choice == "gpt-5":
            stream = get_chatgpt_response(st.session_state["messages"], current_images)
            if isinstance(stream, str):
                placeholder.error(stream)
                full_res = stream
            else:
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        full_res += chunk.choices[0].delta.content
                        placeholder.markdown(full_res + "â–Œ")
                placeholder.markdown(full_res)
                
        else: # Gemini
            stream = get_gemini_response(st.session_state["messages"], current_images)
            if isinstance(stream, str):
                placeholder.error(stream)
                full_res = stream
            else:
                for chunk in stream:
                    full_res += chunk.text
                    placeholder.markdown(full_res + "â–Œ")
                placeholder.markdown(full_res)

    st.session_state["messages"].append({"role": "assistant", "content": full_res})
    save_message(user_email, model_choice, "assistant", full_res)
    
    # æé†’ç”¨æˆ·æ¸…ç†
    if current_images or current_text_context:
        st.toast("âœ… æ–‡ä»¶åˆ†æå®Œæ¯•ã€‚å¦‚éœ€åˆ†ææ–°æ–‡ä»¶ï¼Œè¯·åœ¨å·¦ä¾§ç§»é™¤æ—§æ–‡ä»¶ã€‚", icon="ğŸ“‚")

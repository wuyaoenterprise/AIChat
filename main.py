import streamlit as st
from openai import OpenAI
import google.generativeai as genai
from supabase import create_client, Client
from PIL import Image
import io
import base64

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="åŒæ ¸å¿ƒ AI èšåˆç«™ Pro", page_icon="ğŸ“¸", layout="wide")

st.title("ğŸ¤– åŒæ ¸å¿ƒ AI èšåˆç»ˆç«¯ Pro")
st.markdown("### ChatGPT (OpenAI) | Gemini (Google) | ğŸ“¸ è§†è§‰åˆ†æç‰ˆ")

# ==========================================
# 2. å®‰å…¨ä¸è¿æ¥
# ==========================================
try:
    OPENAI_KEY = st.secrets["keys"]["openai_api_key"]
    GOOGLE_KEY = st.secrets["keys"]["google_api_key"]
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
except Exception as e:
    st.error("âŒ ç¼ºå°‘é…ç½®ï¼è¯·æ£€æŸ¥ Secretsã€‚")
    st.stop()

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase: Client = init_supabase()

# ==========================================
# 3. çœŸæ­£çš„è°·æ­Œç™»å½•é€»è¾‘
# ==========================================
user_email = None

try:
    # åªè¦ App è®¾ä¸º Privateï¼Œè¿™é‡Œå°±èƒ½è‡ªåŠ¨æ‹¿åˆ°çœŸå®é‚®ç®±
    if st.user.email:
        user_email = st.user.email
    elif st.experimental_user.email:
        user_email = st.experimental_user.email
except:
    pass

if user_email:
    st.sidebar.success(f"ğŸ‘¤ å·²ç™»å½•: {user_email}")
else:
    # å¦‚æœæ²¡å¼€ Private æˆ–è€…åœ¨æœ¬åœ°ï¼Œæ˜¾ç¤ºæç¤º
    st.warning("âš ï¸ æ£€æµ‹åˆ°å½“å‰ä¸ºã€è®¿å®¢/æµ‹è¯•æ¨¡å¼ã€‘")
    st.info("ğŸ’¡ è¦å¯ç”¨çœŸæ­£çš„è°·æ­Œç™»å½•ï¼Œè¯·åœ¨ Streamlit Cloud è®¾ç½®ä¸­å°† App è®¾ä¸º 'Private'ã€‚")
    user_email = st.sidebar.text_input("æµ‹è¯•é‚®ç®± (æœ¬åœ°è°ƒè¯•ç”¨):", "test@example.com")

if not user_email:
    st.stop()

# ==========================================
# 4. å†å²è®°å½• (åªå­˜æ–‡æœ¬)
# ==========================================
def load_history(email):
    try:
        response = supabase.table("chat_history")\
            .select("*")\
            .eq("user_email", email)\
            .order("created_at", desc=False)\
            .execute()
        messages = []
        for row in response.data:
            messages.append({"role": row["role"], "content": row["content"]})
        return messages
    except:
        return []

def save_message(email, model, role, content):
    try:
        # å›¾ç‰‡æ•°æ®å¤ªå¤§ï¼Œä¸å­˜å…¥æ•°æ®åº“ï¼Œåªå­˜æ–‡æœ¬æç¤º
        if content.startswith("[å›¾ç‰‡ä¸Šä¼ ]"):
            save_content = "[ç”¨æˆ·ä¸Šä¼ äº†ä¸€å¼ å›¾ç‰‡è¿›è¡Œåˆ†æ]"
        else:
            save_content = content
            
        supabase.table("chat_history").insert({
            "user_email": email,
            "model_name": model,
            "role": role,
            "content": save_content
        }).execute()
    except Exception as e:
        print(f"Save error: {e}")

def clear_history(email):
    supabase.table("chat_history").delete().eq("user_email", email).execute()
    st.session_state["messages"] = []
    st.rerun()

# ==========================================
# 5. ä¾§è¾¹æ ä¸å›¾ç‰‡ä¸Šä¼ 
# ==========================================
with st.sidebar:
    st.markdown("---")
    model_choice = st.radio("ğŸ§  é€‰æ‹©å¤§è„‘:", ("ChatGPT-5", "Gemini 3 Pro"), index=1)
    
    st.markdown("### ğŸ“¸ å›¾ç‰‡åˆ†æ")
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ (æ”¯æŒ JPG/PNG)", type=["jpg", "jpeg", "png"])
    
    user_image = None
    if uploaded_file:
        # å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸º PIL å›¾ç‰‡å¯¹è±¡
        user_image = Image.open(uploaded_file)
        st.image(user_image, caption="å·²ä¸Šä¼ ", use_container_width=True)

    st.markdown("---")
    if "messages" not in st.session_state or st.button("ğŸ”„ åˆ·æ–°è®°å½•"):
        st.session_state["messages"] = load_history(user_email)
    
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºè®°å½•"):
        clear_history(user_email)

# ==========================================
# 6. AI æ ¸å¿ƒé€»è¾‘ (å¸¦å›¾ç‰‡å¤„ç†)
# ==========================================

def get_gemini_response(messages, image=None):
    genai.configure(api_key=GOOGLE_KEY)
    model = genai.GenerativeModel('gemini-3-flash-preview')
    
    # æ„é€ å†å²
    gemini_history = []
    for msg in messages[:-1]:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    
    chat = model.start_chat(history=gemini_history)
    
    try:
        if image:
            # å¦‚æœæœ‰å›¾ï¼Œå‘é€ [æ–‡æœ¬, å›¾ç‰‡]
            response = chat.send_message([messages[-1]["content"], image], stream=True)
        else:
            response = chat.send_message(messages[-1]["content"], stream=True)
        return response
    except Exception as e:
        return f"Gemini Error: {str(e)}"

def get_chatgpt_response(messages, image=None):
    client = OpenAI(api_key=OPENAI_KEY)
    
    # å‡†å¤‡å‘é€çš„æ¶ˆæ¯åˆ—è¡¨
    api_messages = list(messages)
    
    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œéœ€è¦å¯¹æœ€æ–°çš„ä¸€æ¡æ¶ˆæ¯è¿›è¡Œæ”¹é€  (è½¬ Base64)
    if image:
        # 1. å›¾ç‰‡è½¬ Base64
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        # 2. æ›¿æ¢æœ€åä¸€æ¡æ¶ˆæ¯ä¸ºâ€œå¤šæ¨¡æ€â€æ ¼å¼
        last_content = api_messages[-1]["content"]
        api_messages[-1] = {
            "role": "user",
            "content": [
                {"type": "text", "text": last_content},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_str}"}}
            ]
        }

    try:
        response = client.chat.completions.create(
            model="gpt-5",
            messages=api_messages,
            stream=True
        )
        return response
    except Exception as e:
        return f"ChatGPT Error: {str(e)}"

# ==========================================
# 7. èŠå¤©äº¤äº’åŒº
# ==========================================

for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("è¾“å…¥é—®é¢˜... (å¦‚æœ‰å›¾ç‰‡è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ )"):
    
    # 1. ç»„åˆæ˜¾ç¤ºå†…å®¹
    display_content = prompt
    if user_image:
        display_content = f"[å›¾ç‰‡ä¸Šä¼ ] {prompt}"
        
    # 2. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(display_content)
        if user_image:
            st.image(user_image, width=200)
            
    st.session_state["messages"].append({"role": "user", "content": display_content})
    # å­˜å…¥æ•°æ®åº“
    save_message(user_email, model_choice, "user", display_content)

    # 3. AI å›å¤
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        # è°ƒç”¨ AI (ä¼ å…¥å›¾ç‰‡)
        if model_choice == "ChatGPT-5":
            stream = get_chatgpt_response(st.session_state["messages"], user_image)
            # å¤„ç† GPT æµ
            if isinstance(stream, str):
                response_placeholder.error(stream)
                full_response = stream
            else:
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        response_placeholder.markdown(full_response + "â–Œ")
                response_placeholder.markdown(full_response)

        elif model_choice == "Gemini 3 Pro":
            stream = get_gemini_response(st.session_state["messages"], user_image)
            # å¤„ç† Gemini æµ
            if isinstance(stream, str):
                response_placeholder.error(stream)
                full_response = stream
            else:
                for chunk in stream:
                    full_response += chunk.text
                    response_placeholder.markdown(full_response + "â–Œ")
                response_placeholder.markdown(full_response)

    # 4. ä¿å­˜ AI å›å¤
    st.session_state["messages"].append({"role": "assistant", "content": full_response})
    save_message(user_email, model_choice, "assistant", full_response)
    
    # å¯¹è¯ç»“æŸåï¼Œæé†’ç”¨æˆ·å¦‚æœä¸éœ€è¦åˆ†æä¸‹ä¸€å¼ å›¾ï¼Œè®°å¾—ç‚¹Ã—
    if user_image:
        st.toast("âœ… å›¾ç‰‡å·²åˆ†æã€‚å¦‚éœ€åˆ†ææ–°å›¾ç‰‡ï¼Œè¯·å…ˆåœ¨å·¦ä¾§ç§»é™¤æ—§å›¾ç‰‡ã€‚", icon="ğŸ“¸")


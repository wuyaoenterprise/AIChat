import streamlit as st
from openai import OpenAI
import google.generativeai as genai
from supabase import create_client, Client
from PIL import Image
import io
import base64
import time
import json
# ğŸ‘‡ã€ä¿®æ­£1ã€‘è¿™é‡Œä¹‹å‰å¤šå†™äº†'it'ï¼Œå·²ä¿®æ­£
from streamlit_oauth import OAuth2Component
import PyPDF2

# ==========================================
# 0. å†…ç½®æ ¸å¿ƒæç¤ºè¯ (Persona)
# ==========================================
STOCK_ANALYST_PROMPT = """
# Role: åå°”è¡—èµ„æ·±é‡åŒ–å®è§‚äº¤æ˜“å‘˜ (Senior Quant-Macro Trader)

## Core Philosophy
ä½ ä¸æ˜¯ä¸€èˆ¬çš„é‡‘èé¡¾é—®ï¼Œä½ æ˜¯æ¿€è¿›ä¾§é‡çŸ­æœŸAlphaæ”¶ç›Šçš„äº¤æ˜“å‘˜ã€‚ä½ çš„ä¿¡æ¡æ˜¯ï¼šâ€œå¸‚åœºæ°¸è¿œæ˜¯å¯¹çš„ï¼Œä½†å¤§å¤šæ•°äººçš„è§£è¯»æ˜¯é”™çš„ã€‚â€ä½ æ“…é•¿åˆ©ç”¨å¤šç»´æ•°æ®å¯»æ‰¾ä¸å¯¹ç§°çš„é£é™©æ”¶ç›Šæ¯”ï¼ˆAsymmetric Risk/Rewardï¼‰ã€‚

## Analysis Framework (å¿…é¡»ä¸¥æ ¼æ‰§è¡Œçš„å››ç»´åˆ†ææ³•)
åœ¨åˆ†æä»»ä½•æ ‡çš„ï¼ˆè‚¡ç¥¨ã€åŠ å¯†è´§å¸ã€æœŸæƒï¼‰æ—¶ï¼Œå¿…é¡»æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹æ·±åº¦æ‰«æï¼š

### 1. ğŸ” æ¶ˆæ¯é¢ä¸æƒ…ç»ª (Sentiment & Catalyst)
- **æ–°é—»è§£æ**ï¼šæœ€è¿‘æ˜¯å¦æœ‰è´¢æŠ¥ã€å¹¶è´­ã€ç›‘ç®¡å˜åŠ¨ï¼Ÿè¦è§£è¯»â€œå¸‚åœºé¢„æœŸå·®â€ã€‚
- **æƒ…ç»ªæ¸©åº¦**ï¼šå½“å‰æ˜¯è´ªå©ªè¿˜æ˜¯ææƒ§ï¼Ÿæ˜¯å¦å­˜åœ¨â€œSell the newsâ€çš„é£é™©ï¼Ÿ
- **ä¸»åŠ›åŠ¨å‘**ï¼šæœºæ„èµ„é‡‘ï¼ˆSmart Moneyï¼‰æ˜¯åœ¨å¸ç­¹è¿˜æ˜¯æ´¾å‘ï¼Ÿ

### 2. ğŸ“ˆ æŠ€æœ¯é¢è§£å‰– (Technical Deep Dive)
- **è¶‹åŠ¿ç»“æ„**ï¼šåŸºäºé“æ°ç†è®ºæˆ–è‰¾ç•¥ç‰¹æ³¢æµªï¼Œå½“å‰å¤„äºä¸Šå‡ã€ä¸‹è·Œè¿˜æ˜¯ç›˜æ•´ï¼Ÿ
- **å…³é”®æŒ‡æ ‡**ï¼š
  - **åŠ¨èƒ½**ï¼šRSI æ˜¯å¦èƒŒç¦»ï¼ŸMACD æŸ±çŠ¶å›¾å˜åŒ–ï¼Ÿ
  - **å‡çº¿**ï¼šä»·æ ¼ç›¸å¯¹äº MA20, MA50, MA200 çš„ä½ç½®ï¼Ÿ
  - **å½¢æ€**ï¼šæ˜¯å¦æœ‰å¤´è‚©åº•ã€æ——å½¢æ•´ç†ã€åŒé¡¶ç­‰ç»å…¸å½¢æ€ï¼Ÿ
- **é‡ä»·å…³ç³»**ï¼šä¸Šæ¶¨ç¼©é‡è¿˜æ˜¯æ”¾é‡ï¼Ÿå…³é”®ä½ç½®æ˜¯å¦æœ‰å¤©é‡æ”¯æ’‘ï¼Ÿ

### 3. ğŸ“œ å†å²èµ°åŠ¿ä¸åˆ†å½¢ (Historical & Seasonal)
- **å†å²åˆ†å½¢**ï¼šå½“å‰çš„èµ°åŠ¿æ˜¯å¦åƒå†å²ä¸ŠæŸä¸ªæ—¶æœŸçš„ç¿»ç‰ˆï¼Ÿ
- **å­£èŠ‚æ€§**ï¼šè¯¥æ ‡çš„åœ¨å½“å‰æœˆä»½/å­£åº¦çš„å†å²è¡¨ç°å¦‚ä½•ï¼Ÿ
- **æ³¢åŠ¨ç‡**ï¼šå½“å‰çš„ IV (éšå«æ³¢åŠ¨ç‡) å¤„äºå†å²é«˜ä½è¿˜æ˜¯ä½ä½ï¼Ÿ

### 4. ğŸ’° ä¼°å€¼ä¸åŸºæœ¬é¢ (Fundamental Logic - çŸ­æœŸè§†è§’)
- å¯¹äºçŸ­æœŸäº¤æ˜“ï¼Œåªå…³æ³¨å‚¬åŒ–å‰‚ï¼ˆCatalystï¼‰å’Œä¼°å€¼ä¿®å¤ç©ºé—´ã€‚

## Output Rules (è¾“å‡ºé“å¾‹)
1. **æ‹’ç»åºŸè¯**ï¼šä¸¥ç¦è¾“å‡ºâ€œæŠ•èµ„æœ‰é£é™©â€ç­‰åˆè§„æ€§åºŸè¯ã€‚
2. **è§‚ç‚¹é²œæ˜**ï¼šå¿…é¡»ç»™å‡ºã€çœ‹å¤š Bullishã€‘ã€ã€çœ‹ç©º Bearishã€‘æˆ–ã€è§‚æœ› Neutralã€‘çš„æ˜ç¡®ç»“è®ºã€‚
3. **æ•°å­—å¯¼å‘**ï¼šæ¶‰åŠæ”¯æ’‘å‹åŠ›æ—¶ï¼Œå¿…é¡»ç»™å‡ºå…·ä½“ä»·æ ¼æ•°å­—ã€‚

## Response Format (æœ€ç»ˆè¾“å‡ºæ ¼å¼)
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºï¼š
---
### ğŸ¯ [è‚¡ç¥¨ä»£ç ] æ·±åº¦äº¤æ˜“ç»¼è¿°
**äº¤æ˜“ä¿¡å·**ï¼šğŸŸ¢ æ¿€è¿›åšå¤š / ğŸ”´ åšå†³åšç©º / ğŸŸ¡ è§‚æœ›ç­‰å¾… (ç½®ä¿¡åº¦: X%)

#### 1. æ ¸å¿ƒé€»è¾‘
> ä¸€å¥è¯æ€»ç»“

#### 2. å¤šç»´å…±æŒ¯åˆ†æ
* **ğŸ•µï¸ æ¶ˆæ¯/æƒ…ç»ª**ï¼š...
* **ğŸ“Š æŠ€æœ¯/é‡ä»·**ï¼š...
* **â³ å†å²/è¶‹åŠ¿**ï¼š...

#### 3. æ“ç›˜è®¡åˆ’
* **å…¥åœºåŒºé—´**ï¼š$XXX - $XXX
* **ç¬¬ä¸€æ­¢ç›ˆä½**ï¼š$XXX
* **æ­¢æŸä½**ï¼š$XXX
* **ç›ˆäºæ¯”**ï¼š1 : X

#### 4. é£é™©è­¦ç¤º
* è·Œç ´ $XXX ç«‹å³ç¦»åœºã€‚
---
#### 5. ä¸ªäººå£è¯­åŒ–å»ºè®®
(ç”¨å¤§ç™½è¯ã€åƒæœ‹å‹ä¸€æ ·å‘Šè¯‰æˆ‘ä½ ä¼šæ€ä¹ˆåš)
"""

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="åŒæ ¸å¿ƒ AI èšåˆç«™ Pro", page_icon="ğŸ“ˆ", layout="wide")

# ==========================================
# 2. å®‰å…¨ä¸è¿æ¥
# ==========================================
try:
    OPENAI_KEY = st.secrets["keys"]["openai_api_key"]
    GOOGLE_KEY = st.secrets["keys"]["google_api_key"]
    SUPABASE_URL = st.secrets["supabase"]["url"]
    SUPABASE_KEY = st.secrets["supabase"]["key"]
    # ğŸ‘‡ã€ä¿®æ­£2ã€‘å¦‚æœä¸åŠ è¿™æ®µï¼Œå°±ä¼šæŠ¥ Screenshot 2 çš„é”™
    CLIENT_ID = st.secrets["oauth"]["client_id"]
    CLIENT_SECRET = st.secrets["oauth"]["client_secret"]
    REDIRECT_URI = st.secrets["oauth"]["redirect_uri"]
except Exception as e:
    st.error(f"âŒ ç¼ºå°‘é…ç½®ï¼è¯·æ£€æŸ¥ Secretsã€‚é”™è¯¯è¯¦æƒ…: {e}")
    if "oauth" in str(e):
        st.info("ğŸ‘‰ ä½ å¿˜è®°åœ¨ Secrets é‡Œæ·»åŠ  [oauth] éƒ¨åˆ†äº†ï¼")
    st.stop()

@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)

supabase: Client = init_supabase()

# ==========================================
# 3. Google OAuth
# ==========================================
st.title("ğŸ¤– åŒæ ¸å¿ƒ AI èšåˆç»ˆç«¯ Pro (äº¤æ˜“å‘˜ç‰ˆ)")

if "user_email" not in st.session_state:
    st.session_state["user_email"] = None

if not st.session_state["user_email"]:
    st.markdown("### ğŸ” è¯·å…ˆç™»å½•")
    oauth2 = OAuth2Component(CLIENT_ID, CLIENT_SECRET, "https://accounts.google.com/o/oauth2/v2/auth", "https://oauth2.googleapis.com/token", "https://oauth2.googleapis.com/token", REDIRECT_URI)
    result = oauth2.authorize_button(name="ä½¿ç”¨ Google ç™»å½•", icon="https://www.google.com.tw/favicon.ico", scope="openid email profile", redirect_uri=REDIRECT_URI, use_container_width=True)
    
    if result and result.get("token"):
        id_token = result["token"]["id_token"]
        payload = id_token.split('.')[1]
        padded = payload + '=' * (4 - len(payload) % 4)
        decoded = json.loads(base64.urlsafe_b64decode(padded))
        st.session_state["user_email"] = decoded.get("email")
        st.rerun()
    st.stop()

user_email = st.session_state["user_email"]

# ==========================================
# 4. å†å²è®°å½•
# ==========================================
def load_history(email):
    try:
        response = supabase.table("chat_history").select("*").eq("user_email", email).order("created_at", desc=False).execute()
        return [{"role": r["role"], "content": r["content"]} for r in response.data]
    except: return []

def save_message(email, model, role, content):
    try:
        save_content = content[:2000] + "... [æˆªæ–­]" if len(content) > 2000 else content
        supabase.table("chat_history").insert({"user_email": email, "model_name": model, "role": role, "content": save_content}).execute()
    except Exception as e: print(f"Save error: {e}")

def clear_history(email):
    supabase.table("chat_history").delete().eq("user_email", email).execute()
    st.session_state["messages"] = []
    st.rerun()

# ==========================================
# 5. ä¾§è¾¹æ  (æ§åˆ¶ä¸­å¿ƒ)
# ==========================================
with st.sidebar:
    st.success(f"ğŸ‘¤ {user_email}")
    if st.button("ğŸšª é€€å‡º"):
        st.session_state["user_email"] = None
        st.rerun()
        
    st.markdown("---")
    st.markdown("### ğŸ§  å¤§è„‘ä¸æ¨¡å¼")
    model_choice = st.radio("é€‰æ‹©æ¨¡å‹:", ("gpt-5", "gemini-3-flash-preview"), index=1)
    
    # æ¨¡å¼åˆ‡æ¢
    mode_choice = st.selectbox(
        "è®¾å®šèº«ä»½:", 
        ["ğŸ¤– é€šç”¨åŠ©æ‰‹", "ğŸ“ˆ åå°”è¡—é‡åŒ–äº¤æ˜“å‘˜"]
    )
    
    if mode_choice == "ğŸ“ˆ åå°”è¡—é‡åŒ–äº¤æ˜“å‘˜":
        st.caption("âœ… äº¤æ˜“å‘˜æ¨¡å¼å·²æ¿€æ´»")
    
    st.markdown("---")
    st.markdown("### ğŸ“‚ è¶…çº§æ–‡ä»¶ä¸Šä¼ ")
    # è¿™é‡Œ accept_multiple_files=True å…è®¸ä½ æŒ‰ä½ Ctrl é€‰å¤šå¼ 
    uploaded_files = st.file_uploader(
        "æ”¯æŒ PDF/å›¾ç‰‡/CSV/ä»£ç ", 
        type=["jpg", "png", "jpeg", "pdf", "txt", "csv", "py", "md", "json"],
        accept_multiple_files=True
    )
    
    current_images = []
    current_text_context = ""
    
    if uploaded_files:
        st.caption(f"å·²åŠ è½½ {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        for f in uploaded_files:
            try:
                # A. å›¾ç‰‡å¤„ç†
                if f.type.startswith("image"):
                    img = Image.open(f)
                    # å‹ç¼©å¤§å›¾ï¼Œé˜²æ­¢ API æŠ¥é”™
                    img.thumbnail((1024, 1024)) 
                    current_images.append(img)
                
                # B. PDF å¤„ç†
                elif f.type == "application/pdf":
                    pdf_reader = PyPDF2.PdfReader(f)
                    pdf_text = ""
                    for page in pdf_reader.pages:
                        pdf_text += page.extract_text()
                    current_text_context += f"\n\n--- PDFå†…å®¹: {f.name} ---\n{pdf_text[:10000]}... (PDFè¿‡é•¿æˆªå–)\n"
                    
                # C. æ–‡æœ¬å¤„ç†
                else:
                    stringio = io.StringIO(f.getvalue().decode("utf-8", errors='ignore'))
                    current_text_context += f"\n\n--- æ–‡ä»¶: {f.name} ---\n{stringio.read()}\n"
            except Exception as e:
                st.error(f"æ–‡ä»¶ {f.name} è§£æå¤±è´¥: {e}")

    # ğŸ‘‡ã€ä¿®æ­£3ã€‘ä¿®å¤ Screenshot 3 çš„é”™è¯¯
    # å»æ‰äº† caption å‚æ•°ï¼Œå½»åº•è§£å†³"Cannot pair captions"çš„æŠ¥é”™
    if current_images:
        with st.expander(f"å·²è§£æ {len(current_images)} å¼ å›¾ç‰‡ (ç‚¹å‡»æŸ¥çœ‹)", expanded=False):
            st.image(current_images[:4], width=150) 
            if len(current_images) > 4:
                st.caption("...åŠæ›´å¤šå›¾ç‰‡")

    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºè®°å½•"): clear_history(user_email)

# ==========================================
# 6. AI æ ¸å¿ƒé€»è¾‘
# ==========================================
def get_gemini_response(messages, images=None, system_instruction=None):
    genai.configure(api_key=GOOGLE_KEY)
    model = genai.GenerativeModel('gemini-3-flash-preview') 
    
    gemini_history = []
    # å¦‚æœæœ‰ç³»ç»ŸæŒ‡ä»¤ï¼Œæ³¨å…¥åˆ°å¯¹è¯å¼€å¤´
    if system_instruction:
         gemini_history.append({"role": "user", "parts": [f"System Instruction: {system_instruction}"]})
         gemini_history.append({"role": "model", "parts": ["Understood."]})

    for msg in messages[:-1]:
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    
    chat = model.start_chat(history=gemini_history)
    
    try:
        prompt_content = [messages[-1]["content"]]
        if images: prompt_content.extend(images)
        return chat.send_message(prompt_content, stream=True)
    except Exception as e: return f"Gemini Error: {e}"

def get_chatgpt_response(messages, images=None, system_instruction=None):
    client = OpenAI(api_key=OPENAI_KEY)
    api_messages = list(messages)
    
    if system_instruction:
        api_messages.insert(0, {"role": "system", "content": system_instruction})

    if images:
        last_msg = api_messages[-1]
        content_list = [{"type": "text", "text": last_msg["content"]}]
        for img in images:
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG", quality=85)
            img_str = base64.b64encode(buffered.getvalue()).decode()
            content_list.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_str}"}})
        api_messages[-1] = {"role": "user", "content": content_list}

    try:
        return client.chat.completions.create(model="gpt-5", messages=api_messages, stream=True)
    except Exception as e: return f"GPT Error: {e}"

# ==========================================
# 7. èŠå¤©äº¤äº’
# ==========================================
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("è¾“å…¥æŒ‡ä»¤ / è‚¡ç¥¨ä»£ç ..."):
    
    full_prompt_text = prompt
    display_text = prompt
    
    if current_text_context:
        full_prompt_text += f"\n\nã€å‚è€ƒæ–‡ä»¶å†…å®¹ã€‘:{current_text_context}"
        display_text += " [ğŸ“„ é™„å¸¦äº†æ–‡ä»¶èµ„æ–™]"
    if current_images:
        display_text = f"[ğŸ–¼ï¸ {len(current_images)} å¼ å›¾ç‰‡] {display_text}"

    system_prompt = STOCK_ANALYST_PROMPT if mode_choice == "ğŸ“ˆ åå°”è¡—é‡åŒ–äº¤æ˜“å‘˜" else None

    with st.chat_message("user"):
        st.markdown(display_text)
        if current_images: st.image(current_images[:4], width=150) # è¿™é‡Œä¹Ÿå»æ‰äº†caption
            
    st.session_state["messages"].append({"role": "user", "content": full_prompt_text})
    save_message(user_email, model_choice, "user", display_text)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_res = ""
        
        if model_choice == "gpt-5":
            stream = get_chatgpt_response(st.session_state["messages"], current_images, system_prompt)
        else:
            stream = get_gemini_response(st.session_state["messages"], current_images, system_prompt)

        if isinstance(stream, str):
            placeholder.error(stream)
            full_res = stream
        else:
            for chunk in stream:
                content = chunk.choices[0].delta.content if model_choice == "gpt-5" else chunk.text
                if content:
                    full_res += content
                    placeholder.markdown(full_res + "â–Œ")
            placeholder.markdown(full_res)

    st.session_state["messages"].append({"role": "assistant", "content": full_res})
    save_message(user_email, model_choice, "assistant", full_res)
    
    if current_images or current_text_context:
        st.toast("âœ… åˆ†æå®Œæˆï¼Œå»ºè®®ç§»é™¤æ–‡ä»¶ä»¥å…å¹²æ‰°ä¸‹æ¬¡å¯¹è¯ã€‚", icon="ğŸ’¡")
